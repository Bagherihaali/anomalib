:py:mod:`anomalib.pre_processing.pre_process`
=============================================

.. py:module:: anomalib.pre_processing.pre_process

.. autoapi-nested-parse::

   Pre Process.

   This module contains `PreProcessor` class that applies preprocessing
   to an input image before the forward-pass stage.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.pre_processing.pre_process.PreProcessor



Functions
~~~~~~~~~

.. autoapisummary::

   anomalib.pre_processing.pre_process.get_transforms



Attributes
~~~~~~~~~~

.. autoapisummary::

   anomalib.pre_processing.pre_process.logger


.. py:data:: logger
   

   

.. py:function:: get_transforms(config: Optional[Union[str, albumentations.Compose]] = None, image_size: Optional[Union[int, Tuple]] = None, to_tensor: bool = True) -> albumentations.Compose

   Get transforms from config or image size.

   :param config: Albumentations transforms.
                  Either config or albumentations ``Compose`` object. Defaults to None.
   :type config: Optional[Union[str, A.Compose]], optional
   :param image_size: Image size to transform. Defaults to None.
   :type image_size: Optional[Union[int, Tuple]], optional
   :param to_tensor: Boolean to convert the final transforms into Torch tensor. Defaults to True.
   :type to_tensor: bool, optional

   :raises ValueError: When both ``config`` and ``image_size`` is ``None``.
   :raises ValueError: When ``config`` is not a ``str`` or `A.Compose`` object.

   :returns: Albumentation ``Compose`` object containing the image transforms.
   :rtype: A.Compose

   .. rubric:: Examples

   >>> import skimage
   >>> image = skimage.data.astronaut()

   >>> transforms = get_transforms(image_size=256, to_tensor=False)
   >>> output = transforms(image=image)
   >>> output["image"].shape
   (256, 256, 3)

   >>> transforms = get_transforms(image_size=256, to_tensor=True)
   >>> output = transforms(image=image)
   >>> output["image"].shape
   torch.Size([3, 256, 256])


   Transforms could be read from albumentations Compose object.
   >>> import albumentations as A
   >>> from albumentations.pytorch import ToTensorV2
   >>> config = A.Compose([A.Resize(512, 512), ToTensorV2()])
   >>> transforms = get_transforms(config=config, to_tensor=False)
   >>> output = transforms(image=image)
   >>> output["image"].shape
   (512, 512, 3)
   >>> type(output["image"])
   numpy.ndarray

   Transforms could be deserialized from a yaml file.
   >>> transforms = A.Compose([A.Resize(1024, 1024), ToTensorV2()])
   >>> A.save(transforms, "/tmp/transforms.yaml", data_format="yaml")
   >>> transforms = get_transforms(config="/tmp/transforms.yaml")
   >>> output = transforms(image=image)
   >>> output["image"].shape
   torch.Size([3, 1024, 1024])


.. py:class:: PreProcessor(config: Optional[Union[str, albumentations.Compose]] = None, image_size: Optional[Union[int, Tuple]] = None, to_tensor: bool = True)

   Applies pre-processing and data augmentations to the input and returns the transformed output.

   Output could be either numpy ndarray or torch tensor.
   When `PreProcessor` class is used for training, the output would be `torch.Tensor`.
   For the inference it returns a numpy array.

   :param config: Transformation configurations.
                  When it is ``None``, ``PreProcessor`` only applies resizing. When it is ``str``
                  it loads the config via ``albumentations`` deserialisation methos . Defaults to None.
   :type config: Optional[Union[str, A.Compose]], optional
   :param image_size: When there is no config,
   :type image_size: Optional[Union[int, Tuple[int, int]]], optional
   :param ``image_size`` resizes the image. Defaults to None.:
   :param to_tensor: Boolean to check whether the augmented image is transformed
                     into a tensor or not. Defaults to True.
   :type to_tensor: bool, optional

   .. rubric:: Examples

   >>> import skimage
   >>> image = skimage.data.astronaut()

   >>> pre_processor = PreProcessor(image_size=256, to_tensor=False)
   >>> output = pre_processor(image=image)
   >>> output["image"].shape
   (256, 256, 3)

   >>> pre_processor = PreProcessor(image_size=256, to_tensor=True)
   >>> output = pre_processor(image=image)
   >>> output["image"].shape
   torch.Size([3, 256, 256])


   Transforms could be read from albumentations Compose object.
       >>> import albumentations as A
       >>> from albumentations.pytorch import ToTensorV2
       >>> config = A.Compose([A.Resize(512, 512), ToTensorV2()])
       >>> pre_processor = PreProcessor(config=config, to_tensor=False)
       >>> output = pre_processor(image=image)
       >>> output["image"].shape
       (512, 512, 3)
       >>> type(output["image"])
       numpy.ndarray

   Transforms could be deserialized from a yaml file.
       >>> transforms = A.Compose([A.Resize(1024, 1024), ToTensorV2()])
       >>> A.save(transforms, "/tmp/transforms.yaml", data_format="yaml")
       >>> pre_processor = PreProcessor(config="/tmp/transforms.yaml")
       >>> output = pre_processor(image=image)
       >>> output["image"].shape
       torch.Size([3, 1024, 1024])

   .. py:method:: __call__(self, *args, **kwargs)

      Return transformed arguments.



