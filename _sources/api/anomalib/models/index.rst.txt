:py:mod:`anomalib.models`
=========================

.. py:module:: anomalib.models

.. autoapi-nested-parse::

   Load Anomaly Model.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   cflow/index.rst
   components/index.rst
   dfkde/index.rst
   dfm/index.rst
   draem/index.rst
   fastflow/index.rst
   ganomaly/index.rst
   padim/index.rst
   patchcore/index.rst
   reverse_distillation/index.rst
   stfpm/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.models.Cflow
   anomalib.models.Dfkde
   anomalib.models.Dfm
   anomalib.models.Draem
   anomalib.models.Fastflow
   anomalib.models.Ganomaly
   anomalib.models.Padim
   anomalib.models.Patchcore
   anomalib.models.ReverseDistillation
   anomalib.models.Stfpm




.. py:class:: Cflow(input_size: Tuple[int, int], backbone: str, layers: List[str], pre_trained: bool = True, fiber_batch_size: int = 64, decoder: str = 'freia-cflow', condition_vector: int = 128, coupling_blocks: int = 8, clamp_alpha: float = 1.9, permute_soft: bool = False, lr: float = 0.0001)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PL Lightning Module for the CFLOW algorithm.

   .. py:method:: configure_optimizers(self) -> torch.optim.Optimizer

      Configures optimizers for each decoder.

      .. note::

         This method is used for the existing CLI.
         When PL CLI is introduced, configure optimizers method will be
             deprecated, and optimizers will be configured from either
             config.yaml file or from CLI.

      :returns: Adam optimizer for each decoder
      :rtype: Optimizer


   .. py:method:: training_step(self, batch, _)

      Training Step of CFLOW.

      For each batch, decoder layers are trained with a dynamic fiber batch size.
      Training step is performed manually as multiple training steps are involved
          per batch of input images

      :param batch: Input batch
      :param _: Index of the batch.

      :returns: Loss value for the batch


   .. py:method:: validation_step(self, batch, _)

      Validation Step of CFLOW.

          Similar to the training step, encoder features
          are extracted from the CNN for each batch, and anomaly
          map is computed.

      :param batch: Input batch
      :param _: Index of the batch.

      :returns: Dictionary containing images, anomaly maps, true labels and masks.
                These are required in `validation_epoch_end` for feature concatenation.



.. py:class:: Dfkde(layers: List[str], backbone: str, pre_trained: bool = True, max_training_points: int = 40000, pre_processing: str = 'scale', n_components: int = 16, threshold_steepness: float = 0.05, threshold_offset: int = 12)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   DFKDE: Deep Feature Kernel Density Estimation.

   :param backbone: Pre-trained model backbone.
   :type backbone: str
   :param pre_trained: Boolean to check whether to use a pre_trained backbone.
   :type pre_trained: bool, optional
   :param max_training_points: Number of training points to fit the KDE model.
                               Defaults to 40000.
   :type max_training_points: int, optional
   :param pre_processing: Preprocess features before passing to KDE.
                          Options are between `norm` and `scale`. Defaults to "scale".
   :type pre_processing: str, optional
   :param n_components: Number of PCA components. Defaults to 16.
   :type n_components: int, optional
   :param threshold_steepness: Controls how quickly the value saturates around zero.
                               Defaults to 0.05.
   :type threshold_steepness: float, optional
   :param threshold_offset: Offset of the density function from 0. Defaults to 12.0.
   :type threshold_offset: float, optional

   .. py:method:: configure_optimizers()
      :staticmethod:

      DFKDE doesn't require optimization, therefore returns no optimizers.


   .. py:method:: training_step(self, batch, _batch_idx)

      Training Step of DFKDE. For each batch, features are extracted from the CNN.

      :param batch: Batch containing image filename, image, label and mask
      :type batch: Dict[str, Any]
      :param _batch_idx: Index of the batch.

      :returns: Deep CNN features.


   .. py:method:: on_validation_start(self) -> None

      Fit a KDE Model to the embedding collected from the training set.


   .. py:method:: validation_step(self, batch, _)

      Validation Step of DFKDE.

      Similar to the training step, features are extracted from the CNN for each batch.

      :param batch: Input batch

      :returns: Dictionary containing probability, prediction and ground truth values.



.. py:class:: Dfm(backbone: str, layer: str, pre_trained: bool = True, pooling_kernel_size: int = 4, pca_level: float = 0.97, score_type: str = 'fre')

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   DFM: Deep Featured Kernel Density Estimation.

   :param backbone: Backbone CNN network
   :type backbone: str
   :param layer: Layer to extract features from the backbone CNN
   :type layer: str
   :param pre_trained: Boolean to check whether to use a pre_trained backbone.
   :type pre_trained: bool, optional
   :param pooling_kernel_size: Kernel size to pool features extracted from the CNN.
                               Defaults to 4.
   :type pooling_kernel_size: int, optional
   :param pca_level: Ratio from which number of components for PCA are calculated.
                     Defaults to 0.97.
   :type pca_level: float, optional
   :param score_type: Scoring type. Options are `fre` and `nll`. Defaults to "fre".
   :type score_type: str, optional
   :param nll: for Gaussian modeling, fre: pca feature reconstruction error

   .. py:method:: configure_optimizers() -> None
      :staticmethod:

      DFM doesn't require optimization, therefore returns no optimizers.


   .. py:method:: training_step(self, batch, _)

      Training Step of DFM.

      For each batch, features are extracted from the CNN.

      :param batch: Input batch
      :type batch: Dict[str, Tensor]
      :param _: Index of the batch.

      :returns: Deep CNN features.


   .. py:method:: on_validation_start(self) -> None

      Fit a PCA transformation and a Gaussian model to dataset.


   .. py:method:: validation_step(self, batch, _)

      Validation Step of DFM.

      Similar to the training step, features are extracted from the CNN for each batch.

      :param batch: Input batch
      :type batch: List[Dict[str, Any]]

      :returns: Dictionary containing FRE anomaly scores and ground-truth.



.. py:class:: Draem(anomaly_source_path: Optional[str] = None)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   DRÃ†M: A discriminatively trained reconstruction embedding for surface anomaly detection.

   :param anomaly_source_path: Path to folder that contains the anomaly source images. Random noise will
                               be used if left empty.
   :type anomaly_source_path: Optional[str]

   .. py:method:: training_step(self, batch, _)

      Training Step of DRAEM.

      Feeds the original image and the simulated anomaly
      image through the network and computes the training loss.

      :param batch: Batch containing image filename, image, label and mask
      :type batch: Dict[str, Any]

      :returns: Loss dictionary


   .. py:method:: validation_step(self, batch, _)

      Validation step of DRAEM. The Softmax predictions of the anomalous class are used as anomaly map.

      :param batch: Batch of input images

      :returns: Dictionary to which predicted anomaly maps have been added.



.. py:class:: Fastflow(input_size: Tuple[int, int], backbone: str, pre_trained: bool = True, flow_steps: int = 8, conv3x3_only: bool = False, hidden_ratio: float = 1.0)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PL Lightning Module for the FastFlow algorithm.

   :param input_size: Model input size.
   :type input_size: Tuple[int, int]
   :param backbone: Backbone CNN network
   :type backbone: str
   :param pre_trained: Boolean to check whether to use a pre_trained backbone.
   :type pre_trained: bool, optional
   :param flow_steps: Flow steps.
   :type flow_steps: int, optional
   :param conv3x3_only: Use only conv3x3 in fast_flow model. Defaults to False.
   :type conv3x3_only: bool, optinoal
   :param hidden_ratio: Ratio to calculate hidden var channels. Defaults to 1.0.
   :type hidden_ratio: float, optional

   .. py:method:: training_step(self, batch, _)

      Forward-pass input and return the loss.

      :param batch: Input batch
      :type batch: Tensor
      :param _batch_idx: Index of the batch.

      :returns: Dictionary containing the loss value.
      :rtype: STEP_OUTPUT


   .. py:method:: validation_step(self, batch, _)

      Forward-pass the input and return the anomaly map.

      :param batch: Input batch
      :type batch: Tensor
      :param _batch_idx: Index of the batch.

      :returns: batch dictionary containing anomaly-maps.
      :rtype: dict



.. py:class:: Ganomaly(batch_size: int, input_size: Tuple[int, int], n_features: int, latent_vec_size: int, extra_layers: int = 0, add_final_conv_layer: bool = True, wadv: int = 1, wcon: int = 50, wenc: int = 1, lr: float = 0.0002, beta1: float = 0.5, beta2: float = 0.999)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PL Lightning Module for the GANomaly Algorithm.

   :param batch_size: Batch size.
   :type batch_size: int
   :param input_size: Input dimension.
   :type input_size: Tuple[int,int]
   :param n_features: Number of features layers in the CNNs.
   :type n_features: int
   :param latent_vec_size: Size of autoencoder latent vector.
   :type latent_vec_size: int
   :param extra_layers: Number of extra layers for encoder/decoder. Defaults to 0.
   :type extra_layers: int, optional
   :param add_final_conv_layer: Add convolution layer at the end. Defaults to True.
   :type add_final_conv_layer: bool, optional
   :param wadv: Weight for adversarial loss. Defaults to 1.
   :type wadv: int, optional
   :param wcon: Image regeneration weight. Defaults to 50.
   :type wcon: int, optional
   :param wenc: Latent vector encoder weight. Defaults to 1.
   :type wenc: int, optional

   .. py:method:: _reset_min_max(self)

      Resets min_max scores.


   .. py:method:: configure_optimizers(self) -> List[torch.optim.Optimizer]

      Configures optimizers for each decoder.

      .. note::

         This method is used for the existing CLI.
         When PL CLI is introduced, configure optimizers method will be
             deprecated, and optimizers will be configured from either
             config.yaml file or from CLI.

      :returns: Adam optimizer for each decoder
      :rtype: Optimizer


   .. py:method:: training_step(self, batch, _, optimizer_idx)

      Training step.

      :param batch: Input batch containing images.
      :type batch: Dict
      :param optimizer_idx: Optimizer which is being called for current training step.
      :type optimizer_idx: int

      :returns: Loss
      :rtype: Dict[str, Tensor]


   .. py:method:: on_validation_start(self) -> None

      Reset min and max values for current validation epoch.


   .. py:method:: validation_step(self, batch, _) -> Dict[str, torch.Tensor]

      Update min and max scores from the current step.

      :param batch: Predicted difference between z and z_hat.
      :type batch: Dict[str, Tensor]

      :returns: batch
      :rtype: Dict[str, Tensor]


   .. py:method:: validation_epoch_end(self, outputs)

      Normalize outputs based on min/max values.


   .. py:method:: on_test_start(self) -> None

      Reset min max values before test batch starts.


   .. py:method:: test_step(self, batch, _)

      Update min and max scores from the current step.


   .. py:method:: test_epoch_end(self, outputs)

      Normalize outputs based on min/max values.


   .. py:method:: _normalize(self, scores: torch.Tensor) -> torch.Tensor

      Normalize the scores based on min/max of entire dataset.

      :param scores: Un-normalized scores.
      :type scores: Tensor

      :returns: Normalized scores.
      :rtype: Tensor



.. py:class:: Padim(layers: List[str], input_size: Tuple[int, int], backbone: str, pre_trained: bool = True)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PaDiM: a Patch Distribution Modeling Framework for Anomaly Detection and Localization.

   :param layers: Layers to extract features from the backbone CNN
   :type layers: List[str]
   :param input_size: Size of the model input.
   :type input_size: Tuple[int, int]
   :param backbone: Backbone CNN network
   :type backbone: str
   :param pre_trained: Boolean to check whether to use a pre_trained backbone.
   :type pre_trained: bool, optional

   .. py:method:: configure_optimizers()
      :staticmethod:

      PADIM doesn't require optimization, therefore returns no optimizers.


   .. py:method:: training_step(self, batch, _batch_idx)

      Training Step of PADIM. For each batch, hierarchical features are extracted from the CNN.

      :param batch: Batch containing image filename, image, label and mask
      :type batch: Dict[str, Any]
      :param _batch_idx: Index of the batch.

      :returns: Hierarchical feature map


   .. py:method:: on_validation_start(self) -> None

      Fit a Gaussian to the embedding collected from the training set.


   .. py:method:: validation_step(self, batch, _)

      Validation Step of PADIM.

      Similar to the training step, hierarchical features are extracted from the CNN for each batch.

      :param batch: Input batch
      :param _: Index of the batch.

      :returns: Dictionary containing images, features, true labels and masks.
                These are required in `validation_epoch_end` for feature concatenation.



.. py:class:: Patchcore(input_size: Tuple[int, int], backbone: str, layers: List[str], pre_trained: bool = True, coreset_sampling_ratio: float = 0.1, num_neighbors: int = 9)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PatchcoreLightning Module to train PatchCore algorithm.

   :param input_size: Size of the model input.
   :type input_size: Tuple[int, int]
   :param backbone: Backbone CNN network
   :type backbone: str
   :param layers: Layers to extract features from the backbone CNN
   :type layers: List[str]
   :param pre_trained: Boolean to check whether to use a pre_trained backbone.
   :type pre_trained: bool, optional
   :param coreset_sampling_ratio: Coreset sampling ratio to subsample embedding.
                                  Defaults to 0.1.
   :type coreset_sampling_ratio: float, optional
   :param num_neighbors: Number of nearest neighbors. Defaults to 9.
   :type num_neighbors: int, optional

   .. py:method:: configure_optimizers(self) -> None

      Configure optimizers.

      :returns: Do not set optimizers by returning None.
      :rtype: None


   .. py:method:: training_step(self, batch, _batch_idx)

      Generate feature embedding of the batch.

      :param batch: Batch containing image filename, image, label and mask
      :type batch: Dict[str, Any]
      :param _batch_idx: Batch Index
      :type _batch_idx: int

      :returns: Embedding Vector
      :rtype: Dict[str, np.ndarray]


   .. py:method:: on_validation_start(self) -> None

      Apply subsampling to the embedding collected from the training set.


   .. py:method:: validation_step(self, batch, _)

      Get batch of anomaly maps from input image batch.

      :param batch: Batch containing image filename,
                    image, label and mask
      :type batch: Dict[str, Any]
      :param _: Batch Index
      :type _: int

      :returns: Image filenames, test images, GT and predicted label/masks
      :rtype: Dict[str, Any]



.. py:class:: ReverseDistillation(input_size: Tuple[int, int], backbone: str, layers: List[str], anomaly_map_mode: str, lr: float, beta1: float, beta2: float, pre_trained: bool = True)

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PL Lightning Module for Reverse Distillation Algorithm.

   :param input_size: Size of model input
   :type input_size: Tuple[int, int]
   :param backbone: Backbone of CNN network
   :type backbone: str
   :param layers: Layers to extract features from the backbone CNN
   :type layers: List[str]
   :param pre_trained: Boolean to check whether to use a pre_trained backbone.
   :type pre_trained: bool, optional

   .. py:method:: configure_optimizers(self)

      Configures optimizers for decoder and bottleneck.

      .. note::

         This method is used for the existing CLI.
         When PL CLI is introduced, configure optimizers method will be
             deprecated, and optimizers will be configured from either
             config.yaml file or from CLI.

      :returns: Adam optimizer for each decoder
      :rtype: Optimizer


   .. py:method:: training_step(self, batch, _) -> Dict[str, torch.Tensor]

      Training Step of Reverse Distillation Model.

      Features are extracted from three layers of the Encoder model. These are passed to the bottleneck layer
      that are passed to the decoder network. The loss is then calculated based on the cosine similarity between the
      encoder and decoder features.

      :param batch: Input batch
      :type batch: Tensor
      :param _: Index of the batch.

      :returns: Feature Map


   .. py:method:: validation_step(self, batch, _)

      Validation Step of Reverse Distillation Model.

      Similar to the training step, encoder/decoder features are extracted from the CNN for each batch, and
      anomaly map is computed.

      :param batch: Input batch
      :type batch: Tensor
      :param _: Index of the batch.

      :returns: Dictionary containing images, anomaly maps, true labels and masks.
                These are required in `validation_epoch_end` for feature concatenation.



.. py:class:: Stfpm(input_size: Tuple[int, int], backbone: str, layers: List[str])

   Bases: :py:obj:`anomalib.models.components.AnomalyModule`

   PL Lightning Module for the STFPM algorithm.

   :param input_size: Size of the model input.
   :type input_size: Tuple[int, int]
   :param backbone: Backbone CNN network
   :type backbone: str
   :param layers: Layers to extract features from the backbone CNN
   :type layers: List[str]

   .. py:method:: training_step(self, batch, _)

      Training Step of STFPM.

      For each batch, teacher and student and teacher features are extracted from the CNN.

      :param batch: Input batch
      :type batch: Tensor
      :param _: Index of the batch.

      :returns: Hierarchical feature map


   .. py:method:: validation_step(self, batch, _)

      Validation Step of STFPM.

      Similar to the training step, student/teacher features are extracted from the CNN for each batch, and
      anomaly map is computed.

      :param batch: Input batch
      :type batch: Tensor
      :param _: Index of the batch.

      :returns: Dictionary containing images, anomaly maps, true labels and masks.
                These are required in `validation_epoch_end` for feature concatenation.



