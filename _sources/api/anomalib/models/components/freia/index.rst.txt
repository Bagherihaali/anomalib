:py:mod:`anomalib.models.components.freia`
==========================================

.. py:module:: anomalib.models.components.freia

.. autoapi-nested-parse::

   Framework for Easily Invertible Architectures.

   Module to construct invertible networks with pytorch, based on a graph
   structure of operations.

   Link to the original repo: https://github.com/VLL-HD/FrEIA



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   framework/index.rst
   modules/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.models.components.freia.SequenceINN
   anomalib.models.components.freia.AllInOneBlock




.. py:class:: SequenceINN(*dims: int, force_tuple_output=False)

   Bases: :py:obj:`anomalib.models.components.freia.modules.base.InvertibleModule`

   Simpler than FrEIA.framework.GraphINN.

   Only supports a sequential series of modules (no splitting, merging,
   branching off).
   Has an append() method, to add new blocks in a more simple way than the
   computation-graph based approach of GraphINN. For example:
   .. code-block:: python
      inn = SequenceINN(channels, dims_H, dims_W)
      for i in range(n_blocks):
          inn.append(FrEIA.modules.AllInOneBlock, clamp=2.0, permute_soft=True)
      inn.append(FrEIA.modules.HaarDownsampling)
      # and so on

   .. py:method:: append(self, module_class, cond=None, cond_shape=None, **kwargs)

      Append a reversible block from FrEIA.modules to the network.

      :param module_class: Class from FrEIA.modules.
      :param cond: index of which condition to use (conditions will be passed as list to forward()).
                   Conditioning nodes are not needed for SequenceINN.
      :type cond: int
      :param cond_shape: the shape of the condition tensor.
      :type cond_shape: tuple[int]
      :param \*\*kwargs: Further keyword arguments that are passed to the constructor of module_class (see example).


   .. py:method:: __getitem__(self, item)

      Get item.


   .. py:method:: __len__(self)

      Get length.


   .. py:method:: __iter__(self)

      Iter.


   .. py:method:: output_dims(self, input_dims: List[Tuple[int]]) -> List[Tuple[int]]

      Output Dims.


   .. py:method:: forward(self, x_or_z: torch.Tensor, c: Iterable[torch.Tensor] = None, rev: bool = False, jac: bool = True) -> Tuple[torch.Tensor, torch.Tensor]

      Execute the sequential INN in forward or inverse (rev=True) direction.

      :param x_or_z: input tensor (in contrast to GraphINN, a list of
                     tensors is not supported, as SequenceINN only has
                     one input).
      :param c: list of conditions.
      :param rev: whether to compute the network forward or reversed.
      :param jac: whether to compute the log jacobian

      :returns: network output.
                jac (Tensor): log-jacobian-determinant.
      :rtype: z_or_x (Tensor)



.. py:class:: AllInOneBlock(dims_in, dims_c=[], subnet_constructor: Callable = None, affine_clamping: float = 2.0, gin_block: bool = False, global_affine_init: float = 1.0, global_affine_type: str = 'SOFTPLUS', permute_soft: bool = False, learned_householder_permutation: int = 0, reverse_permutation: bool = False)

   Bases: :py:obj:`anomalib.models.components.freia.modules.base.InvertibleModule`

   Module combining the most common operations in a normalizing flow or similar model.

   It combines affine coupling, permutation, and global affine transformation
   ('ActNorm'). It can also be used as GIN coupling block, perform learned
   householder permutations, and use an inverted pre-permutation. The affine
   transformation includes a soft clamping mechanism, first used in Real-NVP.
   The block as a whole performs the following computation:
   .. math::
       y = V\\,R \\; \\Psi(s_\\mathrm{global}) \\odot \\mathrm{Coupling}\\Big(R^{-1} V^{-1} x\\Big)+ t_\\mathrm{global}
   - The inverse pre-permutation of x (i.e. :math:`R^{-1} V^{-1}`) is optional (see
     ``reverse_permutation`` below).
   - The learned householder reflection matrix
     :math:`V` is also optional all together (see ``learned_householder_permutation``
     below).
   - For the coupling, the input is split into :math:`x_1, x_2` along
     the channel dimension. Then the output of the coupling operation is the
     two halves :math:`u = \\mathrm{concat}(u_1, u_2)`.
     .. math::
         u_1 &= x_1 \\odot \\exp \\Big( \\alpha \\; \\mathrm{tanh}\\big( s(x_2) \\big)\\Big) + t(x_2) \\\\
         u_2 &= x_2
     Because :math:`\\mathrm{tanh}(s) \\in [-1, 1]`, this clamping mechanism prevents
     exploding values in the exponential. The hyperparameter :math:`\\alpha` can be adjusted.

   .. py:method:: _construct_householder_permutation(self)

      Compute a permutation matrix.

      Compute a permutation matrix from the reflection vectors that are
      learned internally as nn.Parameters.


   .. py:method:: _permute(self, x, rev=False)

      Perform permutation.

      Performs the permutation and scaling after the coupling operation.
      Returns transformed outputs and the LogJacDet of the scaling operation.


   .. py:method:: _pre_permute(self, x, rev=False)

      Permute before the coupling block, only used if reverse_permutation is set.


   .. py:method:: _affine(self, x, a, rev=False)

      Perform affine coupling operation.

      Given the passive half, and the pre-activation outputs of the
      coupling subnetwork, perform the affine coupling operation.
      Returns both the transformed inputs and the LogJacDet.


   .. py:method:: forward(self, x, c=[], rev=False, jac=True)

      See base class docstring.


   .. py:method:: output_dims(self, input_dims)

      Output Dims.



