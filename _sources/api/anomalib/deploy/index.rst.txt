:py:mod:`anomalib.deploy`
=========================

.. py:module:: anomalib.deploy

.. autoapi-nested-parse::

   Functions for Inference and model deployment.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   inferencers/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   optimize/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   anomalib.deploy.Inferencer
   anomalib.deploy.OpenVINOInferencer
   anomalib.deploy.TorchInferencer



Functions
~~~~~~~~~

.. autoapisummary::

   anomalib.deploy.export_convert
   anomalib.deploy.get_model_metadata



.. py:class:: Inferencer

   Bases: :py:obj:`abc.ABC`

   Abstract class for the inference.

   This is used by both Torch and OpenVINO inference.

   .. py:method:: load_model(self, path: Union[str, pathlib.Path])
      :abstractmethod:

      Load Model.


   .. py:method:: pre_process(self, image: numpy.ndarray) -> Union[numpy.ndarray, torch.Tensor]
      :abstractmethod:

      Pre-process.


   .. py:method:: forward(self, image: Union[numpy.ndarray, torch.Tensor]) -> Union[numpy.ndarray, torch.Tensor]
      :abstractmethod:

      Forward-Pass input to model.


   .. py:method:: post_process(self, predictions: Union[numpy.ndarray, torch.Tensor], meta_data: Optional[Dict[str, Any]]) -> Dict[str, Any]
      :abstractmethod:

      Post-Process.


   .. py:method:: predict(self, image: Union[str, numpy.ndarray, pathlib.Path], meta_data: Optional[Dict[str, Any]] = None) -> anomalib.post_processing.ImageResult

      Perform a prediction for a given input image.

      The main workflow is (i) pre-processing, (ii) forward-pass, (iii) post-process.

      :param image: Input image whose output is to be predicted.
                    It could be either a path to image or numpy array itself.
      :type image: Union[str, np.ndarray]
      :param meta_data: Meta-data information such as shape, threshold.

      :returns: Prediction results to be visualized.
      :rtype: ImageResult


   .. py:method:: _superimpose_segmentation_mask(self, meta_data: dict, anomaly_map: numpy.ndarray, image: numpy.ndarray)

      Superimpose segmentation mask on top of image.

      :param meta_data: Metadata of the image which contains the image size.
      :type meta_data: dict
      :param anomaly_map: Anomaly map which is used to extract segmentation mask.
      :type anomaly_map: np.ndarray
      :param image: Image on which segmentation mask is to be superimposed.
      :type image: np.ndarray

      :returns: Image with segmentation mask superimposed.
      :rtype: np.ndarray


   .. py:method:: __call__(self, image: numpy.ndarray) -> anomalib.post_processing.ImageResult

      Call predict on the Image.

      :param image: Input Image
      :type image: np.ndarray

      :returns: Prediction results to be visualized.
      :rtype: ImageResult


   .. py:method:: _normalize(self, anomaly_maps: Union[torch.Tensor, numpy.ndarray], pred_scores: Union[torch.Tensor, numpy.float32], meta_data: Union[Dict, omegaconf.DictConfig]) -> Tuple[Union[numpy.ndarray, torch.Tensor], float]

      Applies normalization and resizes the image.

      :param anomaly_maps: Predicted raw anomaly map.
      :type anomaly_maps: Union[Tensor, np.ndarray]
      :param pred_scores: Predicted anomaly score
      :type pred_scores: Union[Tensor, np.float32]
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
      :type meta_data: Dict

      :returns:

                Post processed predictions that are ready to be visualized and
                    predicted scores.
      :rtype: Tuple[Union[np.ndarray, Tensor], float]


   .. py:method:: _load_meta_data(self, path: Optional[Union[str, pathlib.Path]] = None) -> Union[omegaconf.DictConfig, Dict]

      Loads the meta data from the given path.

      :param path: Path to JSON file containing the metadata.
                   If no path is provided, it returns an empty dict. Defaults to None.
      :type path: Optional[Union[str, Path]], optional

      :returns: Dictionary containing the metadata.
      :rtype: Union[DictConfig, Dict]



.. py:class:: OpenVINOInferencer(config: Union[str, pathlib.Path, omegaconf.DictConfig, omegaconf.ListConfig], path: Union[str, pathlib.Path, Tuple[bytes, bytes]], meta_data_path: Union[str, pathlib.Path] = None)

   Bases: :py:obj:`anomalib.deploy.inferencers.base_inferencer.Inferencer`

   OpenVINO implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: Union[str, Path, DictConfig, ListConfig]
   :param path: Path to the openvino onnx, xml or bin file.
   :type path: Union[str, Path]
   :param meta_data_path: Path to metadata file. Defaults to None.
   :type meta_data_path: Union[str, Path], optional

   .. py:method:: load_model(self, path: Union[str, pathlib.Path, Tuple[bytes, bytes]])

      Load the OpenVINO model.

      :param path: Path to the onnx or xml and bin files
                   or tuple of .xml and .bin data as bytes.
      :type path: Union[str, Path, Tuple[bytes, bytes]]

      :returns:

                Input and Output blob names
                    together with the Executable network.
      :rtype: [Tuple[str, str, ExecutableNetwork]]


   .. py:method:: pre_process(self, image: numpy.ndarray) -> numpy.ndarray

      Pre process the input image by applying transformations.

      :param image: Input image.
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: np.ndarray


   .. py:method:: forward(self, image: numpy.ndarray) -> numpy.ndarray

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: np.ndarray

      :returns: Output predictions.
      :rtype: np.ndarray


   .. py:method:: post_process(self, predictions: numpy.ndarray, meta_data: Optional[Union[Dict, omegaconf.DictConfig]] = None) -> Dict[str, Any]

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: np.ndarray
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to None.
      :type meta_data: Dict, optional

      :returns: Post processed prediction results.
      :rtype: Dict[str, Any]



.. py:class:: TorchInferencer(config: Union[str, pathlib.Path, omegaconf.DictConfig, omegaconf.ListConfig], model_source: Union[str, pathlib.Path, anomalib.models.components.AnomalyModule], meta_data_path: Union[str, pathlib.Path] = None)

   Bases: :py:obj:`anomalib.deploy.inferencers.base_inferencer.Inferencer`

   PyTorch implementation for the inference.

   :param config: Configurable parameters that are used
                  during the training stage.
   :type config: Union[str, Path, DictConfig, ListConfig]
   :param model_source: Path to the model ckpt file or the Anomaly model.
   :type model_source: Union[str, Path, AnomalyModule]
   :param meta_data_path: Path to metadata file. If none, it tries to load the params
                          from the model state_dict. Defaults to None.
   :type meta_data_path: Union[str, Path], optional

   .. py:method:: _load_meta_data(self, path: Optional[Union[str, pathlib.Path]] = None) -> Union[Dict, omegaconf.DictConfig]

      Load metadata from file or from model state dict.

      :param path: Path to metadata file. If none, it tries to load the params
                   from the model state_dict. Defaults to None.
      :type path: Optional[Union[str, Path]], optional

      :returns: Dictionary containing the meta_data.
      :rtype: Dict


   .. py:method:: load_model(self, path: Union[str, pathlib.Path]) -> anomalib.models.components.AnomalyModule

      Load the PyTorch model.

      :param path: Path to model ckpt file.
      :type path: Union[str, Path]

      :returns: PyTorch Lightning model.
      :rtype: (AnomalyModule)


   .. py:method:: pre_process(self, image: numpy.ndarray) -> torch.Tensor

      Pre process the input image by applying transformations.

      :param image: Input image
      :type image: np.ndarray

      :returns: pre-processed image.
      :rtype: Tensor


   .. py:method:: forward(self, image: torch.Tensor) -> torch.Tensor

      Forward-Pass input tensor to the model.

      :param image: Input tensor.
      :type image: Tensor

      :returns: Output predictions.
      :rtype: Tensor


   .. py:method:: post_process(self, predictions: torch.Tensor, meta_data: Optional[Union[Dict, omegaconf.DictConfig]] = None) -> Dict[str, Any]

      Post process the output predictions.

      :param predictions: Raw output predicted by the model.
      :type predictions: Tensor
      :param meta_data: Meta data. Post-processing step sometimes requires
                        additional meta data such as image shape. This variable comprises such info.
                        Defaults to None.
      :type meta_data: Dict, optional

      :returns: Post processed prediction results.
      :rtype: Dict[str, Union[str, float, np.ndarray]]



.. py:function:: export_convert(model: anomalib.models.components.AnomalyModule, input_size: Union[List[int], Tuple[int, int]], onnx_path: Union[str, pathlib.Path], export_path: Union[str, pathlib.Path])

   Export the model to onnx format and convert to OpenVINO IR.

   :param model: Model to convert.
   :type model: AnomalyModule
   :param input_size: Image size used as the input for onnx converter.
   :type input_size: Union[List[int], Tuple[int, int]]
   :param onnx_path: Path to output onnx model.
   :type onnx_path: Union[str, Path]
   :param export_path: Path to exported OpenVINO IR.
   :type export_path: Union[str, Path]


.. py:function:: get_model_metadata(model: anomalib.models.components.AnomalyModule) -> Dict[str, torch.Tensor]

   Get meta data related to normalization from model.

   :param model: Anomaly model which contains metadata related to normalization.
   :type model: AnomalyModule

   :returns: metadata
   :rtype: Dict[str, Tensor]


